{"cells":[{"cell_type":"markdown","metadata":{"id":"pYy5d5Q2AD0C"},"source":["# Day1: **1:1 문의 내용 기반 문의유형 자동 분류 모델링**"]},{"cell_type":"markdown","metadata":{"id":"zLR44IVKAD0D"},"source":["* [미션0] 오늘의 목표\n","* [미션1] 개발환경 설정하기\n","* [미션2] 데이터 전처리하기\n","* [미션3] 단어사전 만들기\n","* [미션4] 모델 학습 데이터 생성\n","* [미션5] 모델 생성하기\n","* [미션6] 분류 모델 고도화\n","* <도전미션> 테스트 데이터를 활용한 모델 성능 뽐내기"]},{"cell_type":"markdown","metadata":{"id":"5PaKDhugAD0D"},"source":["----------"]},{"cell_type":"markdown","metadata":{"id":"YC-kDUydAD0E"},"source":["### <span style=\"color:green;background-color:#fff5b1\"> [미션0] 오늘의 목표: </span><span style=\"color:red;background-color:#fff5b1\">1:1 문의 자동분류 모델링</span>"]},{"cell_type":"markdown","metadata":{"id":"UBFjXJ-uAD0E"},"source":["* 1:1 문의 분석팀에는 AIVLE 1:1 문의의 답변을 위해 문의 내용을 일일이 확인하여 분야별 담당 전문 튜터에게 전달해야 합니다.\n","* 그러나 수많은 1:1 문의를 읽고 분야를 나누는 일은 많은 리소스와 시간이 필요 합니다.\n","* 특히 최근 일반 문의가 코드 문의에 섞여 들어오는 일이 점점 증가 하고 있습니다.\n","* 코드문의와 일반문의를 자동으로 구별할 수 있는 자연어 처리 딥러닝 모델을 생성하고 테스트 데이터를 통해 모델을 고도화 해주세요.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"60xdoBhQAD0E"},"source":["### <span style=\"color:green;background-color:#fff5b1\">[미션1] 개발환경 설정하기</span>"]},{"cell_type":"markdown","metadata":{"id":"Lb_J7U8MAD0E"},"source":["1:1 문의 자동 분류기를 만들기 위하여 필요한 라이브러리와 데이터를 불러 옵니다.\n","* 필요 라이브러리를 호출하기\n","* 데이터 파일 불러오기\n","* 불필요 컬럼 삭제하기\n","* '\\n'(줄바꿈문자 또는 개행문자) 삭제하기\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DohFpbV9AD0E","outputId":"4d0ceb0e-4567-4b7a-8b0f-f98c6185b07e"},"outputs":[],"source":["# 필요 라이브러리를 호출하기\n","## 필요한 라이브러리는 추가로 불러 오세요.\n","## 프로젝트를 진행하며 필요한 라이브러리는 추가로 설치 하세요.\n","\n","import pandas as pd    # pandas 데이터프레임을 생성/편집하기 위해 사용 합니다.\n","import numpy as np    # numpy 행렬을 생성/편집하기 위해 사용 합니다.\n","# import os    # 시스템에 접근하기 위해 사용 합니다.\n","# import joblib    # 오브젝트를 파일로 저장하기 위해 사용 합니다.\n","\n","from tqdm import tqdm   # 실행되고 있는 셀의 진행 상황을 보기 위해 사용 합니다.\n","from collections import Counter    # 단어의 수를 카운트하기 위해 사용 합니다.\n","import re    # 정규표현식을 사용하기 위해 사용 합니다.\n","# from konlpy.tag import Okt # 문장을 형태소 단위로 분리하기 위해 사용합니다.\n","\n","from sklearn.model_selection import train_test_split    # 학습할 데이터를 나눌때 사용 합니다.\n","# from sklearn.preprocessing import OneHotEncoder    # 컬럼의 고유한 값에 따라 1과 0으로 열을 생성해 줍니다.\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer    # 문장을 단어로 나누어 줍니다.\n","from tensorflow.keras.preprocessing.sequence import pad_sequences    # 지정한 칸만큼  빈 공간을 0으로 채워 줍니다.\n","\n","from tensorflow.keras.models import Sequential    # # 딥러닝 인공신경망을 생성하는데 사용합니다.\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, SimpleRNN  # 인공신경망의 기능별 레이어를 구성하는데 사용합니다.\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint    # 모델 학습 시 자원절약을 위해 사용됩니다.\n","\n","\n","from sklearn.metrics import confusion_matrix    # 모델의 예측결과를 효율적으로 표현해 줍니다.\n","from sklearn.metrics import classification_report    # 모델의 결과를 각 지표에 따라 보여 줍니다.\n","\n","import matplotlib.pyplot as plt    # 데이터를 각종 차트로 시각화하기 위해 사용 합니다.\n","import seaborn as sns    # 데이터를 각종 차트로 시각화하기 위해 사용 합니다.\n","\n","font_path = 'malgun.ttf' # 워드클라우드 한글 폰트 사용\n","\n","\n","plt.rcParams['font.family'] = 'Malgun Gothic'\n","plt.rcParams['axes.unicode_minus'] = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxZCJJHEAD0F","outputId":"066ebf38-5b19-45ac-b0cf-4975ec9a434b"},"outputs":[],"source":["# 데이터 파일 불러오기\n","## 'QnA_train_data.csv' 파일 불러와 train_df 변수에 할당 합니다.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxWXCkluAD0G","outputId":"b56ac2e8-43e4-490b-f6ac-52d829ccf350"},"outputs":[],"source":["# 불필요 컬럼 삭제하기\n","## drop 함수를 사용하여 필요없는 컬럼을 삭제 합니다.\n","## 삭제할 컬럼: ['트랙', '지역']\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4-hlQcYtAD0G","outputId":"4e26017a-15c2-48f3-8c1a-7e1e3cb4579a"},"outputs":[],"source":["# '\\n'(줄바꿈문자 또는 개행문자) 삭제하기\n","## 줄바꿈문자는 워드클라우드에서 에러를 일으켜 삭제 해야 합니다.\n","## 반복문을 사용하여 data['문의내용']의 각 열에서 '\\n'을 ' '으로 변경 한 후\n","## 다시 data['문의내용']에 넣어 줍니다.\n","\n"," \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ksJoFyAvAD0G"},"source":["### <span style=\"color:green;background-color:#fff5b1\"> [미션2] 데이터 전처리하기</span>"]},{"cell_type":"markdown","metadata":{"id":"i4suZQCSAD0G"},"source":["자연어 처리는 일반 데이터에 비해 많은 자원과 시간을 사용합니다.\n","많은 시간과 자원을 절약하고 모델의 성능을 높이기 위해서 특수문자 제거, 불용어 제거 등 특별한 데이터 클렌징을 시행 합니다.\n","데이터 클렌징에 정해진 방법은 없습니다.\n","코드셀의 설명을 따라 최고의 성능을 낼 수 있도록 데이터 클렌징(전처리)를 시행해 주세요.\n","\n","* 특수문자 제거하기\n","* 단어 분리하기\n","* 불용어 제거하기\n","* 한글자 단어 제거하기\n","* 문의 길이(단어 개수) 측정하기\n","* 문의별 단어의 수 시각화하기\n","* 문의별 단어의 수(cleansing_length) 기초통계량 확인하기\n","* 문의 길이(단어 개수) 상한선 정하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyiuPlwxAD0G"},"outputs":[],"source":["# [실행코드] 특수문자 제거 함수 실행\n","## 아래의 함수 생성 코드를 실행해 주세요\n","## 아래의 특수문자 이외의 특수문제 제거가 필요한 경우 자유롭게 추가하여 사용하세요.\n","\n","removal_list =  \"‘, ’, ◇, ‘, ”,  ’, ', ·, \\“, ·, △, ●,  , ■, (, ), \\\", >>, `, /, #, ∼, =,ㆍ<,>, .,?, !,【,】, …, ◆,%, ₩\"\n","def remove_special(sentence: str = None):\n","\n","    sentence = re.sub(\"[.,\\'\\\"’‘”“!?]\", \"\", sentence)\n","    sentence = re.sub(\"[^ㄱ-ㅎ가-힣a-zA-Z\\\\s]\", \" \", sentence)\n","    sentence = re.sub(\"\\s+\", \" \", sentence)\n","    sentence = sentence.translate(str.maketrans(removal_list, ' '*len(removal_list)))\n","    sentence = sentence.strip()\n","    sentence = sentence.replace('\\n', ' ')\n","\n","    return sentence\n","\n","# [실행코드] 특수문자를 제거하는 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V080T42kAD0G","outputId":"c57e20f9-cf30-43a6-a396-28098ecee5ba"},"outputs":[],"source":["# 특수문자 제거하기\n","## data['문의내용'] 각 행에서 특수 문제를 제거 후 결과를 담을 data['특수문자제거'] 빈 열을 생성 합니다.\n","## remove_special 함수를 사용하여 data['문의내용']의 각 행에서 특수문자를 제거하고 data['특수문자제거'] 열에 결과를 할당해 주세요.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GnGInaNwAD0H","outputId":"4f929af0-b403-4772-96d9-3656ff5d05c5"},"outputs":[],"source":["# 단어 분리하기\n","## data['특수문자제거'] 각 행의 문장을 단어의 모음으로 분리 한 결과를 담을 data['단어분리'] 빈 열을 생성 합니다.\n","## data['특수문자제거']의 각 행의 문장을 띄어쓰기(' ') 기준으로 split 하여 같은 행의 data['단어분리'] 열에 할당 합니다.\n","## [참고] 딥러닝 시간에 배운 KoNLPy 라이브러리의 Okt 형태소 분석기를 사용해도 됩니다.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o69lGITRAD0G"},"outputs":[],"source":["# [실행코드] 조사, 인사말, 불용어 제거 함수 실행\n","## 아래의 함수 생성 코드를 실행해 주세요\n","## 아래의 불용어 이외의 불용어 제거가 필요한 경우 자유롭게 추가하여 사용하세요. \n","\n","def remove_stopword(sent):\n","    stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','을','으로','자','에','와','한','이', '로', '에서', '하는', '하면', '하고', '요', '혹시', '합니다', '감사합니다', '안녕하세요']\n","    removed = [word for word in sent if not word in stopwords] # 불용어 제거\n","    return removed\n","\n","# [실행코드] 조사, 인사말, 불용어를 제거하는 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRLeB6ajAD0H","outputId":"fb2e5985-ca5e-4ff0-91a3-28f8e1e3b30a"},"outputs":[],"source":["# 불용어 제거하기하기\n","## 자연어를 예측할 때 데이터에 조사, 접속사, 감탄사, 인사말 등이 포함되면 불필요한 자원 및 시간을 사용 할 수 있습니다.\n","## 불필요한 자원사용 방지를 위해 데이터에서 불용어를 제거해 줍니다.\n","## data['단어분리'] 에서 불용어를 제한 한 뒤 결과를 담을 data['불용어제거'] 열을 생성해 줍니다.\n","## remove_stopword 함수를 사용하여 data['단어분리']에서 불용어를 제거하고 결과를 data['불용어제거'] 열에 할당 합니다.\n","## 모델의 정확도 향상을 위해 제거하고 싶은 불용어가 있을 경우 remove_stopword 함수의 stopwords 변수에 추가해 주세요.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZ8EnHFAAD0H","outputId":"3536f23d-b1de-45bb-bda7-cad6c1e783a4"},"outputs":[],"source":["# 한글자 단어 제거하기\n","## 한글자 단어는 단어의 중요도에 비해 빈도수가 너무 높아 모델 정확도 향상에 방해가 될 수 있습니다.\n","## data['불용어제거'] 에 각 행에서 한글자 단어를 제거 후 결과를 담을 data['한글자제거'] 빈 열을 추가 합니다.\n","## 각 행마다 한글자 단어를 제거후 남은 단어들을 담을 data['한글자제거'] 열을 생성 합니다.\n","## 반복문을 사용하여 data['불용어제거'] 의 각 행에서 단어 추출하고 단어의 글자수(len)을 측정하여 2글자 이상인 단어만 data['한글자제거'] 열에 할당해 줍니다.\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsJjsJlKAD0H","outputId":"243809e2-dfb9-4484-b541-7474941c9c23"},"outputs":[],"source":["# 문의 길이(단어 개수) 측정하기\n","## data['한글자제거']열의 한 행에 몇 개의 단어가 있는지 len 함수를 사용하여 계산 합니다.\n","## cleansing_length 변수를 리스트 타입으로 생성후 초기화 합니다.\n","## 반복문을 사용하여 data['한글자제거']의 각 행의 단어의 수를 계산하여 cleansing_length 변수에 append 합니다.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ZXqN2uOAD0H","outputId":"423e730d-86f7-4bd8-83b0-bd0b32883225"},"outputs":[],"source":["# 문의별 단어의 수 시각화하기\n","## 데이터 전처리를 통해 data['문의내용']에서 불필요한 단어를 제거하는 데이터 클렌징을 시행하였습니다.\n","## 나중에 적절한 Padding 값 산출을 위하여 데이터의 문장 길이(단어수)가 어떻게 분포 되어 있는지 클렌징한 데이터를 가지고 시각화 합니다.\n","## 챠트는 histplot 과 boxplot 두가지를 생성하세요.\n","## 챠트의 크기는 보기 좋게 자율적으로 설정 합니다.\n","## 그리드를 표현해 주세요.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cYV43eTAD0H","outputId":"45af8b59-9e67-46e5-b46a-9ca3d52a15ef"},"outputs":[],"source":["# 문의별 단어의 수(cleansing_length) 기초통계량 확인하기\n","## .describe 매서드를 사용하여 cleansing_length 변수의 기초통계량을 확인 합니다.\n","## 리스트 타입의 변수는 .describe 매서드를 사용할 수 없으니 pd.Series 타입으로 변경하여 확인 합니다.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AoslcLbhAD0H"},"outputs":[],"source":["# 문의 길이(단어 개수) 상한선 정하기\n","## 딥러닝 모델에 입력되는 데이터는 그 길이가 같아야 합니다.\n","## 자연어 처리에 입력의 길이를 똑같이 맞추기 위해 데이터의 앞 또는 뒤에 0을 삽입하는 Padding 기법을 적용합니다.\n","## 적절한 Padding 값을 도출하기 위해 max_length 변수를 생성하고 cleansing_length 변수의 기초통계량 90% 백분위수 값을 할당해 주세요.\n","## 특정 백분위수 값을 도출할 때는 .quantile() 매서드를 사용합니다.\n","## 리스트 타입의 변수는 .quantile() 매서드를 사용할 수 없으니 pd.Series 타입으로 변경하여 사용 합니다.\n","## .quantile() 매서드의 출력값 데이터 타입은 float 이므로 int 형으로 변경하여 max_length 에 할당해 주세요.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wgJqw3pVAD0H"},"source":["### <span style=\"color:green;background-color:#fff5b1\">[미션3] 단어사전 만들기</span>"]},{"cell_type":"markdown","metadata":{"id":"ntyIVs3PAD0H"},"source":["AI가 자연어 처리를하기위해 우리가 쓰는 단어를 숫자 형태로 바꾸어 저장한 단어사전을 사용합니다.<br>\n","단어사전은 모델이 학습에 고려할 단어들을 모아 숫자로 인덱스화 시켜 놓은 것 입니다. <br>\n","그런데 1:1 문의 데이터에는 쓰임이 거의 없어 성능에 영향을 미치지는 않지만 자원을 소모하는 단어들이 많이 있습니다.<br>\n","단어사전 생성시 이러한 쓰임이 적은 단어를 제거하여 모델의 효율을 높일 수 있습니다.<br>\n","단어의 빈도수를 계산하여 쓰임이 많은 단어를 골라 단어사전을 생성해 주세요.<br>\n","* 단어 모으기\n","* 전체 단어 빈도수 카운트하기\n","* 전체 단어 빈도수 및 합계 확인하기\n","* 희귀 단어 빈도수 및 합계 확인하기\n","* 전체 단어에서 희귀 단어수가 차지하는 비율 계산하기\n","* 단어사전 크기 정하기\n","* 단어사전(단어 인덱스화) 생성하기\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYr1eGPzAD0I"},"outputs":[],"source":["# 단어 모으기\n","\n","## 사용이 많은 중요 단어를 도출하고 단어별 빈도수를 카운트하기위해 데이터에서 단어만 가져와서 모아야 합니다.\n","## 다중 반복문을 사용하여 data['한글자제거'] 각 행의 단어들만 가져와 word_list 변수를 리스트로 생성하고 단어들을 append 해 주세요.\n","## 단어를 각 행별로 분리하여 모으지 않고 모든 행을 통합하여 단어를 모아야 합니다.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LenewQgHAD0I","outputId":"6cb179a9-59c5-4137-ba6b-ffdca45d1889"},"outputs":[],"source":["# 전체 단어 빈도수 카운트하기\n","## Counter 함수를 사용하여 word_list 변수에 포함된 각 단어의 빈도수를 산출하여 word_count에 할당 합니다.\n","## 할당 후 .most_common 매서드를 사용하여 어떤 단어들이 많이 사용되었는지 확인 합니다.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdmaT_dOAD0I","outputId":"b17ccf7c-b5aa-41c4-f029-1aa820586c3a"},"outputs":[],"source":["# 전체 단어 빈도수 및 합계 확인하기\n","## word_count 변수에서 .values() 매서드를 사용하여 값 만 분리하고 word_frequency에 할당합니다.\n","## len 함수를 사용하여 total_frequency의 크기(각 값의 개수)를 total_count 변수에 할당 합니다.\n","## sum 함수 사용하여 total_frequency의 각 값의 총 합을 계산하여 total_frequency_sum 변수에 할당 합니다.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7-QI5WWAD0I","outputId":"68dd5eb9-aaf9-463c-ef18-83ff5673a8bc"},"outputs":[],"source":["# 희귀 단어 빈도수 및 합계 확인하기\n","## word_count 변수에서 .values() 매서드를 사용하여 한번만 사용된 단어만 분리하여 rare_frequency에 할당합니다.\n","## len 함수를 사용하여 rare_frequency의 크기(각 값의 개수)를 rare_count 변수에 할당 합니다.\n","## sum 함수 사용하여 rare_frequency의 각 값의 총 합을 계산하여 rare_frequency_sum 변수에 할당 합니다.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s5XyMUmvAD0I","outputId":"3b9117bf-4a25-4992-c51e-cfe4e591f2f0"},"outputs":[],"source":["# 전체 단어에서 희귀 단어수가 차지하는 비율 계산하기\n","## 전체 단어 개수에서 희귀 단어개 수가 차지하는 비율을 계산해서 rare_count_percent 할당 합니다.\n","## 전체 단어의 사용 빈도수 합에서 희귀 단어의 사용 빈도수 합이차지하는 비율을 계산해서 rare_frequency_percent 할당 합니다.\n","## 희귀 단어가 전체 단어에서 얼만큼의 비중이 있는지 각 값들을 출력 합니다.\n","\n","\n","\n","\n","print(\"데이터의 전체 단어 수: \",           )\n","print(\"데이터 내 전체 희귀 단어수: \",          )\n","print(\"\\n\")\n","print(\"데이터의 전체 단어의 빈도 수 합: \",          )\n","print(\"데이터 내 전체 희귀 단어의 빈도 수 합: \",            )\n","print(\"전체 단어에서 희귀 단어가 차지하는 비율: \",                    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3WLXlgAAD0I","outputId":"bba88447-441d-4f24-c61e-13bba4c55154"},"outputs":[],"source":["# 단어사전 크기 정하기\n","## 전체 단어 수에서 희귀단어 수가 차지하는 비율은 매우 높은데 비해 사용 빈도수는 저조 합니다.\n","## 희귀 단어들이 모델 학습에 포함되지 않도록 단어사전의 크기를 설정하여 제한 합니다.\n","## 단어사전의 크기 = 전체 단어 수 - 희귀 단어수\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDN_PydVAD0I","outputId":"a637d1ec-6885-4f6e-877b-7b07c2f04780"},"outputs":[],"source":["# 단어사전(단어 인덱스화) 생성하기\n","## 단어사전을 생성하기 위해서 설정한 단어사전의 크기에 맞게 쓰임이 많은 단어 부터 인덱스를 부합니다.\n","## keras Tokenizer 함수를 이용하여 단어에 인덱스를 부여해 단어사전을 생성해 주세요.(토크나이즈)\n","## 단어사전을 생성 할 때, 사전에 불필요한 단어까지 포함되지 않도록 위에서 설정한 vocab_size 이용하여 tokenizer 파라미터를 설정해서 초기화 하세요.\n","## [TIP] keras tokenizer 참고 사이트: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gTVrFVIEAD0I"},"source":["### <span style=\"color:green;background-color:#fff5b1\">[미션4] 모델 학습 데이터 생성</span>"]},{"cell_type":"markdown","metadata":{"id":"Cfd46B2IAD0I"},"source":["모델의 학습을 위하여 학습 데이터를 생성해야 합니다.<br>\n","모델의 Y(target) 데이터는 data['문의유형'] 데이터 이고, X(Feature)는 1:1 문장을 토큰화 한 data['토큰화'] 데이터 입니다.\n","그러나 현재의 형태로는 1:1 문의 자동분류 모델을 학습 시킬수 없습니다.\n","모델을 학습 시킬 수 있도록 데이터를 전처리 해주세요.\n","* data['문의유형'] 데이터 변경하기\n","* Y(target) 데이터 분리하기\n","* X(Feature) 데이터 분리 및 padding 적용하기\n","* 학습 데이터 분리하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kDnI3smAD0J"},"outputs":[],"source":["# data['문의유형'] 데이터 변경하기\n","## 코드 관련 문의와 코드 이외 문의의 카테고리를 나눠 주세요.\n","## data['문의유형'] 값 중 '코드1', '코드2'는 1로, 그 외 값들은 0으로 변경해 주세요.\n","## [TIP] 변경할 값은 type_dict 변수의 딕셔너리를 참조 하세요.\n","\n","\n","type_dict = {\n","    '코드1': 1,\n","    '코드2': 1,\n","    '웹': 0,\n","    '이론': 0,\n","    '시스템 운영': 0,\n","    '원격': 0\n","}\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLUiKkfCAD0J","outputId":"4eb20efb-ecf7-4227-f4e4-7d575672496a"},"outputs":[],"source":["# Y(target) 데이터 분리하기\n","## 모델 학습에 Y(target) 으로 사용할 data['문의유형'] 열을 분리하여 y_data 변수에 할당 합니다.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mnU4H7KAD0J","outputId":"f4185ab7-02b2-4486-c941-65640c92ddf3"},"outputs":[],"source":["# X(Feature) 데이터 분리 및 padding 적용하기\n","## 모델을 학습시키기 위해서 모든 X(Feature) 데이터의 길이는 같아야 합니다.\n","## 즉, 모델 학습에 사용할 data['토큰화'] 의 길이가 행마다 다 같아야 합니다.\n","## pad_sequences 함수를 사용하여 모든 행의 길이를 맞추어 x_data 변수에 할당해 주세요.\n","## 이때 데이터의 길이 제한은 전체 문장의 90%가 포함될 수 있도록 max_length 변수의 값으로 설정해 주세요.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trZ1EYiOAD0J"},"outputs":[],"source":["# 학습 데이터 분리하기\n","## 모델을 학습시킬 데이터를 train_test_split 매서드를 사용하여 학습 데이터 7, 검증 데이터로 3 비율로 나누어 줍니다.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EgEqmwmzAD0J"},"source":["### <span style=\"color:green;background-color:#fff5b1\">[미션5] 모델 생성하기</span>"]},{"cell_type":"markdown","metadata":{"id":"RjznzmJ2AD0M"},"source":["1:1 문의 자동 분류기는 입력된 자연어를 코드/일반 문의로 나눌 수 있는 2진 분류기 입니다.\n","2진 분류 자연어 처리에 알맞게 딥러닝 Layer 를 설계하고, 2진 분류에 맞는 활성화 함수를 지정하여 최고의 분류 성능을 도출해 주세요.\n","\n","\n","* 딥러닝 모델 생성하기\n","* 모델 학습하기\n","* 결과 예측하기\n","* 예측 결과 변경하기\n","* 이진분류 모델 평가하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JbJEaSDBAD0M","outputId":"f9581e84-df12-4cb4-f5af-a3f1091e85dd"},"outputs":[],"source":["# 딥러닝 모델 생성하기\n","## 딥러닝 모델 생성을 위해 keras 라이브러리를 사용합니다.\n","## 입력층 shape 는 미리 설정한 max_length 으로 지정 합니다.\n","## Embedding 층을 추가하여 입력 데이터를 벡터화 해주세요.\n","## Embedding 층 입력 차원은 vocab_size 변수 값과 같습니다.\n","## 히든레이어 층은 최고의 성능이 나올수 있도록 자유롭게 작성 합니다.\n","## 출력층의 노드는 분류 하려는 Class 개수와 동일합니다.\n","## 활성화 함수는 이진 분류에 알맞은 함수를 사용합니다.\n","## 모델 compile 시 사용할 손실 함수는 이진 분류에 알맞은 함수를 사용합니다.\n","## 모델의 Layer 설계는 Sequential 함수를 사용해서 생성해도 됩니다.\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRajke2nAD0M","outputId":"adc3f97f-1573-43dd-e68a-1dc0c56d48ac"},"outputs":[],"source":["# 모델 학습하기\n","## 생성한 모델에 x_train, y_train를 적용하여 모델을 학습 시킵니다.\n","## epochs, batch_size, validation_split 은 최고의 성능이 나올 수 있도록 자유롭게 작성 합니다.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmUlyOrYAD0M","outputId":"d47e391d-e8c9-471c-a649-2988affb6115"},"outputs":[],"source":["# 결과 예측하기\n","## 검증용 x_val 사용해서 결과를 예측 합니다.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-5za7MbAD0M"},"outputs":[],"source":["# 예측 결과 변경하기\n","## 예측 된 결과는 0~1 사이에 실수 값으로 출력 됩니다.\n","## 검증 데이터(y_val)와 비교 할 수 있도록 정수 형태로 변경 합니다.\n","## 반올림을 적용하여 예측값이 0.5 이상이면 1, 미만이면 0 으로 변경해 주세요.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPGA5P2ZAD0M","outputId":"a115b423-c41c-4806-dda4-8b6143a7a172"},"outputs":[],"source":["# 이진분류 모델 평가하기\n","## y_val 검증 데이터를 사용하여 모델의 성능을 평가 합니다.\n","## 평가는 confusion_matrix, classification_report 를 사용하여 평가 합니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jtAS-IHSAD0M"},"source":["### <span style=\"color:green;background-color:#fff5b1\">[미션6] 분류 모델 고도화</span>"]},{"cell_type":"markdown","metadata":{"id":"ffA7tM7JAD0M"},"source":["- 모델의 고도화 위해 데이터 클렌징 방법 변경, 다른 모델 사용, 인공신경망 레이어 조정 등 다양한 기법을 사용하여 1:1 문의 자동 분류 모델의 정확도를 개선해 주세요.<br>\n","- 우리조의 모델 설계 내용을 정리하여 최고 성능 도출 방법을 소개해 주세요.<br>\n","<br><br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"xk6pdgoxAD0M"},"source":["----------\n","----------"]},{"cell_type":"markdown","metadata":{"id":"_Cushoz2AD0N"},"source":["### <span style=\"color:red;background-color:#fff5b1\"><도전미션> 테스트 데이터를 활용한 모델 성능 뽐내기 </span>"]},{"cell_type":"markdown","metadata":{"id":"DSvmZyyvAD0N"},"source":["* QnA_test_data.csv 파일에는 추가 문의에 대한 데이터가 있습니다.\n","* QnA_test_data.csv 파일 불러와 문의에 대한 분류 결과값을 예측해 봅니다.\n","* QnA_test_data.csv 데이터셋은 전처리가 되어 있지 않습니다.\n","* 우리조 만의 데이터 클렌징 방법과 모델링 기법을 활용하여 Test 데이터 에서의 최고의 성능을 도출해 주세요.\n","* <도전미션>은 아래의 가이드 코드와 셀을 무시하고 자유롭게 코드를 작성하세요.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"rbzxgUxfAD0O"},"source":["----------\n","----------\n"]},{"cell_type":"markdown","metadata":{"id":"cDAIyTXXAD0O"},"source":["----------\n"]},{"cell_type":"markdown","metadata":{"id":"3hCU4iZQAD0O"},"source":["# 수고 많으셨습니다"]},{"cell_type":"markdown","metadata":{"id":"67hgcZStAD0O"},"source":["----------"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
