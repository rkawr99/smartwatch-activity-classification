네이버제트 제페토 제휴 데이터 분석/운영 체험형 인턴 자기소개서
1. 본 직무에 지원하게 된 동기와, 내가 이 포지션에 가장 적합한 후보라고 생각하는 이유를 작성해주세요.
전자공학을 전공하면서도 데이터가 만들어내는 비즈니스 가치에 매력을 느껴 6개월간 집중적으로 데이터 분석 분야로 커리어를 전환해왔습니다. 이 과정에서 쌓아온 실무 프로젝트 경험을 제페토라는 글로벌 플랫폼의 실제 비즈니스 환경에서 검증하고 한 단계 더 발전시키고 싶어 지원하게 되었습니다. 특히 4.6억이라는 방대한 사용자 데이터 속에서 브랜드 제휴 프로젝트의 진짜 성과를 찾아내고, 이를 통해 더 나은 파트너십 전략을 만들어가는 큰 의미를 느끼고 싶습니다.

제가 이 포지션에 가장 적합한 후보라고 생각하는 이유는 실무에서 바로 활용 가능한 검증된 데이터 분석 경험을 보유하고 있기 때문입니다. Google BigQuery에서 170만 건 규모의 배달앱 데이터를 SQL로 분석하며 52,823명 사용자의 25주간 행동 패턴을 분석했습니다. 이 과정에서 56.78%라는 높은 휴면 사용자 비율을 발견하고, 신규 사용자의 90%가 1주 내 이탈한다는 치명적 문제점을 찾아냈습니다. 단순히 문제를 발견하는 데 그치지 않고 1주차 리텐션을 8%에서 20%로 개선하고 휴면율을 57%에서 40%로 감소시키는 구체적인 목표와 6가지 실행 방안까지 제시했습니다.

또한 6개월간 매일 8시간 이상 투자하여 SQLD, 컴퓨터활용능력 1급, AICE Associate 자격증을 연속으로 취득한 것은 꼼꼼하고 성실한 업무 태도를 보여주는 객관적 증거입니다. 이러한 체계적 학습 능력과 끈기는 제페토의 복잡한 브랜드 제휴 데이터를 분석하고 의미 있는 인사이트를 도출하는 데 필수적인 역량이라고 확신합니다.

2. 최근 참여했던 프로모션이나 이벤트를 소개하고, 해당 경험에 대해 상세히 설명해주세요.
최근 SQL에 대한 심층적인 공부를 하면서 GA/Firebase 형태로 만들어진 배달앱 데이터를 BigQuery로 분석하여 배달앱 사용자 리텐션 개선을 위한 종합 전략을 수립하는 프로젝트에 참여했습니다. 2022년 8월부터 2023년 1월까지의 운영 데이터를 활용해 비즈니스 임팩트를 창출할 수 있는 구체적인 개선 방안을 제안하는 것이 목표였습니다.

프로젝트 초기에는 Google BigQuery에서 52,823명 사용자의 1,713,921건 이벤트 데이터를 수집하고 분석 가능한 형태로 가공하는 작업부터 시작했습니다. 가장 중요했던 것은 사용자를 휴면, 복귀, 기존, 신규로 명확하게 세분화하는 분류 기준을 설계하는 것이었는데, 이를 통해 각 사용자 그룹별 특성과 문제점을 정확히 파악할 수 있었습니다.

심화 분석 단계에서는 전체 고객 여정을 추적하기 위해 퍼널 분석을 실시했습니다. Screen View에서 시작해 Login, Category, Restaurant, Food, Cart를 거쳐 최종 Payment까지 각 단계별 전환율을 측정한 결과, 100%에서 시작해 21.71%로 떨어지는 극심한 이탈률을 확인했습니다. 특히 Restaurant에서 Food 단계로 넘어가는 지점에서 67.53%에서 40.73%로 급격히 떨어지는 것을 발견했고, 이것이 가장 중요한 개선 포인트임을 알 수 있었습니다.

코호트별 리텐션 분석을 통해서는 더욱 충격적인 사실을 발견했습니다. 신규 사용자의 무려 90%가 첫 주 안에 이탈한다는 것이었습니다. 또한 계절성 분석 결과 연말과 신년 사이에 전환율이 33%나 차이 나는 것도 확인했습니다. 이러한 분석 결과를 바탕으로 온보딩 프로세스 개선, 휴면 유저 리액티베이션 캠페인, 계절성 대응 전략 등 6가지 구체적인 개선 방안을 제시했고, 각각에 대해 측정 가능한 KPI 목표까지 설정했습니다. 이 경험을 통해 데이터 분석이 단순한 수치 확인이 아니라 실제 비즈니스 문제를 해결하는 강력한 도구라는 것을 깨달았습니다.

3. 예상치 못한 문제의 발생으로 계획대로 일이 진행되지 않았을 때, 책임감을 가지고 적극적으로 문제를 해결한 경험과 교훈을 구체적으로 서술해주세요.
스마트워치 센서 데이터 기반 행동 분류 머신러닝 프로젝트를 진행하던 중, Random Forest 알고리즘을 사용해 6가지 행동 패턴(서기, 앉기, 눕기, 걷기, 계단 오르기, 계단 내려가기)을 분류하는 것이 목표였고, 초기 결과도 97.5%라는 높은 정확도를 보여주어 만족스러웠습니다. 하지만 곧 예상치 못한 문제에 직면하게 되었습니다.

실제 현장에서 활용 가능한 모델을 만들기 위해 더 깊이 분석하던 중, 클래스 불균형 문제가 심각하다는 것을 발견했습니다. 'LAYING' 클래스는 1,115개의 샘플이 있는 반면, '계단 내려 가기'는 791개에 불과했습니다. 단순히 전체 정확도만 높다고 해서 모든 행동을 제대로 분류한다고 볼 수 없었습니다. 실제로 혼동 행렬을 자세히 분석해보니 특정 행동 패턴에서는 오분류가 빈번하게 발생하고 있었고, 이는 실무에서 치명적인 문제가 될 수 있었습니다.

문제 해결을 위해  561개의 센서 특성들을 features.csv 파일을 통해 체계적으로 분석하면서, 어떤 센서 그룹이 어떤 행동 분류에 더 중요한지 파악했습니다. 그리고 SMOTE 기법을 도입하여 부족한 클래스의 합성 데이터를 생성하기로 결정했습니다. 단순히 데이터를 복제하는 것이 아니라 k-최근접 이웃을 활용해 새로운 합성 샘플을 만들어 클래스 균형을 맞추는 접근법이었습니다.

또한 전체 데이터에 SMOTE를 적용하면 데이터 누수 문제가 생길 수 있어, 훈련 세트에만 적용하고 검증 세트는 원본 데이터를 유지해야 했습니다. 이 과정에서 교차 검증 전략을 새롭게 설계해야 했고, Borderline-SMOTE  등 다양한 변형 기법들도 실험해보며 데이터 특성에 가장 적합한 방법을 찾아갔습니다.  이 경험을 통해 머신러닝에서 단순한 정확도 수치보다 실제 비즈니스 가치를 창출할 수 있는 견고한 모델의 중요성을 깨달았습니다. 특히 클래스 불균형 문제는 실제 현장에서 자주 발생하는 이슈이며, 이를 해결하는 다양한 기법들을 실무에 적용할 수 있는 역량을 기를 수 있었습니다.
