{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"B_iAjwPm_mYg"},"source":["# Image Data Augmentation Exercise : CIFAR-100\n","---\n","## 데이터가 더 부족한 세상으로!\n","\n","[여기 참고](https://www.cs.toronto.edu/~kriz/cifar.html)"]},{"cell_type":"markdown","source":["## Data Loading"],"metadata":{"id":"PxJ6_9sW1Shc"}},{"cell_type":"code","metadata":{"id":"CzL95VmTBHxx"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.datasets.cifar100 import load_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPKBI9NAlkbm"},"source":["(train_x, train_y), (test_x, test_y) = load_data()\n","# (train_x, train_y), (test_x, test_y) = load_data(label_mode='coarse')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.unique(train_y)"],"metadata":{"id":"Hl1ud8ijn5dG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_dict = {0:'apple', 1: 'aquarium_fish', 2: 'baby', 3: 'bear', 4: 'beaver', 5: 'bed', 6: 'bee', 7: 'beetle', 8: 'bicycle', 9: 'bottle',\n","              10: 'bowl', 11: 'boy',12: 'bridge',13: 'bus',14: 'butterfly',15: 'camel',16: 'can',17: 'castle',18: 'caterpillar',19: 'cattle',\n","              20: 'chair',21: 'chimpanzee',22: 'clock',23: 'cloud',24: 'cockroach',25: 'couch',26: 'cra',27: 'crocodile',28: 'cup',29: 'dinosaur',\n","              30: 'dolphin',31: 'elephant',32: 'flatfish',33: 'forest',34: 'fox',35: 'girl',36: 'hamster',37: 'house',38: 'kangaroo',39: 'keyboard',\n","              40: 'lamp',41: 'lawn_mower',42: 'leopard',43: 'lion',44: 'lizard',45: 'lobster',46: 'man',47: 'maple_tree',48: 'motorcycle',49: 'mountain',\n","              50: 'mouse',51: 'mushroom',52: 'oak_tree',53: 'orange',54: 'orchid',55: 'otter',56: 'palm_tree',57: 'pear',58: 'pickup_truck',59: 'pine_tree',\n","              60: 'plain',61: 'plate',62: 'poppy',63: 'porcupine',64: 'possum',65: 'rabbit',66: 'raccoon',67: 'ray',68: 'road',69: 'rocket',\n","              70: 'rose',71: 'sea',72: 'seal',73: 'shark',74: 'shrew',75: 'skunk',76: 'skyscraper',77: 'snail',78: 'snake',79: 'spider',\n","              80: 'squirrel',81: 'streetcar',82: 'sunflower',83: 'sweet_pepper',84: 'table',85: 'tank',86: 'telephone',87: 'television',88: 'tiger',89: 'tractor',\n","              90: 'train',91: 'trout',92: 'tulip',93: 'turtle',94: 'wardrobe',95: 'whale',96: 'willow_tree',97: 'wolf',98: 'woman',99: 'worm'\n","            }\n","\n","label_dict[0]"],"metadata":{"id":"JICCaf3motkl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 데이터 살펴보기"],"metadata":{"id":"e6XuQQHCmy4O"}},{"cell_type":"code","source":["rand_i = np.random.randint(0, train_x.shape[0])\n","\n","plt.title(f'idx: {rand_i} , class: { label_dict[train_y[rand_i][0]] }')\n","plt.imshow( train_x[rand_i] )\n","plt.show()"],"metadata":{"id":"EEQXdv1lm2Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rows = 5\n","fig, axes = plt.subplots(rows, len(label_dict), figsize=(len(label_dict), rows) )\n","\n","for img_id in range(len(label_dict)) :\n","    imgs = train_x[train_y.reshape(-1)==img_id]\n","    imgs_len = len(imgs)\n","\n","    for row_i in range(rows) :\n","        axe = axes[row_i, img_id]\n","        axe.imshow( imgs[np.random.randint(imgs_len)], interpolation='none' )\n","        axe.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"6loqEpmfvHcD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Preprocessing"],"metadata":{"id":"vZaHfXvD9xE-"}},{"cell_type":"markdown","source":["* Data split\n","    - training set : test set = 8 : 2\n","    - training set : validation set = 8 : 2\n","    - 재현을 위한 난수 고정 : 2023"],"metadata":{"id":"3KQ1J6HQe10N"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"kemxUotVlGYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.2, random_state=2023)\n","train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=2023)"],"metadata":{"id":"3zWLncQExpgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x.shape, train_y.shape"],"metadata":{"id":"CFqMfYt-x3ip"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Scaling\n","\n","    - min-max scaling"],"metadata":{"id":"L6wdqmy9xglU"}},{"cell_type":"code","source":["tr_r_max, tr_r_min = train_x[:,:,:,0].max(), train_x[:,:,:,0].min()\n","tr_g_max, tr_g_min = train_x[:,:,:,1].max(), train_x[:,:,:,1].min()\n","tr_b_max, tr_b_min = train_x[:,:,:,2].max(), train_x[:,:,:,2].min()"],"metadata":{"id":"9ugHSqbxQbTg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tr_r_mm = (train_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\n","tr_g_mm = (train_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\n","tr_b_mm = (train_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)"],"metadata":{"id":"7tD0ae1AQrs-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_mm = np.stack((tr_r_mm, tr_g_mm, tr_b_mm), axis=3)"],"metadata":{"id":"nZW0nNDxQ7St"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_r_mm = (val_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\n","val_g_mm = (val_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\n","val_b_mm = (val_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)"],"metadata":{"id":"cOcuYNNinG8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_x_mm = np.stack((val_r_mm, val_g_mm, val_b_mm), axis=3)"],"metadata":{"id":"zGxAHgcQnOCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["te_r_mm = (test_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\n","te_g_mm = (test_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\n","te_b_mm = (test_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)"],"metadata":{"id":"6ln6UiJtRIE1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_x_mm = np.stack((te_r_mm, te_g_mm, te_b_mm), axis=3)"],"metadata":{"id":"Mk2zHq3FRaLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_mm[:,:,:,0].max(), train_x_mm[:,:,:,0].min()"],"metadata":{"id":"VvBcZ2qkRVSJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_mm.shape"],"metadata":{"id":"h-hJZvVGRgNC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* One-hot encoding"],"metadata":{"id":"u7VEtyVIxgeW"}},{"cell_type":"code","source":["class_n = len(np.unique(train_y))\n","class_n"],"metadata":{"id":"Zb9nkEkalITR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical"],"metadata":{"id":"XVvQ4lZSyZyD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y = to_categorical(train_y, class_n)\n","val_y = to_categorical(val_y, class_n)\n","test_y = to_categorical(test_y, class_n)"],"metadata":{"id":"1V0Bym5oydlu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Data shape 재확인"],"metadata":{"id":"X072_BHJzpcF"}},{"cell_type":"code","source":["train_x.shape, train_y.shape"],"metadata":{"id":"h41qEPDYAoxj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXUbrQWBxiq3"},"source":["## **Image Data Augmentation**\n","\n","- ImageDataGenerator : [**전체 옵션 참고**](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n","- .flow( )"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"jkIDyQCZsCNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainIDG = ImageDataGenerator(rotation_range=20,\n","                               width_shift_range=0.2,\n","                               height_shift_range=0.2,\n","                               shear_range=0.15,\n","                               zoom_range=0.15,\n","                               horizontal_flip=False,\n","                               vertical_flip=True)\n","\n","valIDG = ImageDataGenerator()"],"metadata":{"id":"QbHfeuz8sCLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["flow_trainIDG = trainIDG.flow(train_x, train_y)\n","flow_valIDG = valIDG.flow(val_x, val_y)"],"metadata":{"id":"oOOxp8r1sCIB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k8DUObakz7lD"},"source":["## Modeling : CNN\n","\n","- 조건\n","    1. Sequential API, Functiona API 중 택일.\n","    2. [이 구조를 미니 버전으로 활용해봐도 좋다.](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99DFA5415B38AC752E)\n","    3. DropOut, BatchNormalization 등의 기능도 같이 활용해보자.\n","    4. Early Stopping을 사용할 것."]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n","from tensorflow.keras.layers import Conv2D, MaxPool2D"],"metadata":{"id":"vIoGQgPl1Fuy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Sequential API"],"metadata":{"id":"w8vprnF4g9nA"}},{"cell_type":"code","source":["# 1. 세션 클리어\n","clear_session()\n","\n","# 2. 모델 선언\n","model1 = Sequential()\n","\n","# 3. 레이어 블록 조립\n","model1.add( Input(shape=(32,32,3)) )\n","\n","model1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n","                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","                   activation='relu',   # 빼먹지 않게 주의!\n","                   ) )\n","model1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n","                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","                   activation='relu',   # 빼먹지 않게 주의!\n","                   ) )\n","model1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n","                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n","                      ) )\n","model1.add( BatchNormalization() )\n","model1.add( Dropout(0.2) )\n","\n","model1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n","                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","                   activation='relu',   # 빼먹지 않게 주의!\n","                   ) )\n","model1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n","                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","                   activation='relu',   # 빼먹지 않게 주의!\n","                   ) )\n","model1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n","                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n","                      ) )\n","model1.add( BatchNormalization() )\n","model1.add( Dropout(0.2) )\n","\n","model1.add( Flatten() )\n","model1.add( Dense(256, activation='relu') )\n","model1.add( Dense(100, activation='softmax') )\n","\n","# 4. 컴파일\n","model1.compile(optimizer='adam', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model1.summary()"],"metadata":{"id":"R4GQukNf0RiU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Functional API"],"metadata":{"id":"ptCExKiAhAgZ"}},{"cell_type":"code","source":["# 1. 세션 클리어\n","clear_session()\n","\n","# 2. 레이어 엮기\n","il = Input(shape=(32,32,3))\n","\n","hl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","            strides=(1,1),       # Conv2D 필터의 이동 보폭\n","            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","            activation='relu',   # 빼먹지 않게 주의!\n","            )(il)\n","hl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","            strides=(1,1),       # Conv2D 필터의 이동 보폭\n","            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","            activation='relu',   # 빼먹지 않게 주의!\n","            )(hl)\n","hl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n","               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n","               )(hl)\n","hl = BatchNormalization()(hl)\n","hl = Dropout(0.2)(hl)\n","\n","hl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","            strides=(1,1),       # Conv2D 필터의 이동 보폭\n","            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","            activation='relu',   # 빼먹지 않게 주의!\n","            )(hl)\n","hl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n","            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n","            strides=(1,1),       # Conv2D 필터의 이동 보폭\n","            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n","            activation='relu',   # 빼먹지 않게 주의!\n","            )(hl)\n","hl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n","               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n","               )(hl)\n","hl = BatchNormalization()(hl)\n","hl = Dropout(0.2)(hl)\n","\n","hl = Flatten()(hl)\n","hl = Dense(256, activation='relu')(hl)\n","ol = Dense(100, activation='softmax')(hl)\n","\n","# 3. 모델의 시작과 끝 지정\n","model2 = Model(il, ol)\n","\n","# 4. 컴파일\n","model2.compile(optimizer='adam', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model2.summary()"],"metadata":{"id":"qdNDLY7qg9RO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* Early Stopping"],"metadata":{"id":"iXn1SFq40RiV"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping"],"metadata":{"id":"IFcmdQFo0RiV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss',          # 얼리 스토핑을 적용할 관측 대상\n","                   min_delta=0,                 # Threshold. 설정한 값 이상으로 변해야 성능 개선되었다고 간주.\n","                   patience=5,                  # 성능 개선이 발생하지 않았을 때, 몇 epoch를 더 지켜볼 것인가.\n","                   verbose=1,\n","                   restore_best_weights=True)   # 성능이 가장 좋은 epoch의 가중치를 적용함."],"metadata":{"id":"olJWlT5-L0yX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* .fit( )\n","    - Data Augmentation 과정에서 생성한 ImageDataGenerator를 사용해야 한다."],"metadata":{"id":"mMCtKeha0RiV"}},{"cell_type":"code","source":["model1.fit(flow_trainIDG,               # 위에서 설정한 ImageDataGenerator를 사용해야 한다!\n","           epochs=20, verbose=1,\n","           validation_data=flow_valIDG, # validation set 역시 ImageDataGenerator를 사용!\n","           callbacks=[es]               # 얼리스토핑 적용\n","           )"],"metadata":{"id":"N0iuxpL_0RiW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* .evaluate( )"],"metadata":{"id":"OADy5fyHGEMd"}},{"cell_type":"code","source":["model1.evaluate(test_x, test_y, verbose=1)"],"metadata":{"id":"fpZMsGCtGEbh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* .predict( )"],"metadata":{"id":"UaqlpwpzhKgL"}},{"cell_type":"code","source":["y_pred = model1.predict(test_x)"],"metadata":{"id":"ajdE3dv9hKgM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원핫 인코딩 한 것을 다시 묶어주는 코드\n","# 평가 지표 및 실제 데이터 확인을 위해 필요\n","\n","y_pred_arg = np.argmax(y_pred, axis=1)\n","test_y_arg = np.argmax(test_y, axis=1)"],"metadata":{"id":"8EDi6-HZGV7T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 평가 지표"],"metadata":{"id":"h0i7gtoKQI2M"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report"],"metadata":{"id":"V0bKlDKAJO6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy_score(test_y_arg, y_pred_arg)"],"metadata":{"id":"xKaSctmxJSR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print( classification_report(test_y_arg, y_pred_arg, target_names=list(label_dict.values())) )"],"metadata":{"id":"cFCAI30pInVp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualization"],"metadata":{"id":"dX0PzsnZGdIh"}},{"cell_type":"markdown","source":["* 실제 데이터 확인"],"metadata":{"id":"iAz06dlD7Gno"}},{"cell_type":"code","source":["rand_idx = np.random.randint(0, len(y_pred_arg))\n","test_idx = test_y_arg[rand_idx]\n","pred_idx = y_pred_arg[rand_idx]\n","class_prob = np.floor( y_pred[rand_idx]*100 )\n","\n","print(f'idx = {rand_idx}')\n","print(f'해당 인덱스의 이미지는 {label_dict[test_idx]}')\n","print(f'모델의 예측 : {label_dict[pred_idx]}')\n","print(f'모델의 클래스별 확률 : ')\n","print('-------------------')\n","for idx, val in enumerate( list(label_dict.values()) ) :\n","    print(val, class_prob[idx])\n","print('=================================================')\n","\n","if test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n","    print('정답')\n","else :\n","    print('땡')\n","\n","plt.imshow(test_x[rand_idx])\n","plt.show()"],"metadata":{"id":"rDzw-qDE7Eoc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 틀린 이미지만 확인해보기"],"metadata":{"id":"v7lHIf-B9Z_L"}},{"cell_type":"code","source":["temp = (test_y_arg == y_pred_arg)\n","false_idx = np.where(temp==False)[0]\n","false_len = len(false_idx)\n","false_len"],"metadata":{"id":"WnLoTiF0LZEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rand_idx = false_idx[np.random.randint(0, false_len)]\n","test_idx = test_y_arg[rand_idx]\n","pred_idx = y_pred_arg[rand_idx]\n","class_prob = np.floor( y_pred[rand_idx]*100 )\n","\n","print(f'idx = {rand_idx}')\n","print(f'해당 인덱스의 이미지는 {label_dict[test_idx]}')\n","print(f'모델의 예측 : {label_dict[pred_idx]}')\n","print(f'모델의 클래스별 확률 : ')\n","print('-------------------')\n","for idx, val in enumerate( list(label_dict.values()) ) :\n","    print(val, class_prob[idx])\n","print('=================================================')\n","\n","if test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n","    print('정답')\n","else :\n","    print('땡')\n","\n","plt.imshow(test_x[rand_idx] )\n","plt.show()"],"metadata":{"id":"bWcCLIW2_ACh"},"execution_count":null,"outputs":[]}]}