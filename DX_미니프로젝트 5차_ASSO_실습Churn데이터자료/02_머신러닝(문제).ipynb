{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8SbOMdy0FT4"
   },
   "source": [
    "# [조별실습] Python을 활용한 AI 모델링 - 머신러닝 파트\n",
    "+ 이번 실습에서는 Python을 활용한 AI 모델링에서 머신러닝에 대해 실습합니다.\n",
    "+ 머신러닝 모델에는 아래와 같은 모델들이 있습니다.\n",
    "+ 단일 분류예측 모델 : 두 개 이상의 클래스 중 하나로 입력 데이터를 분류하는 모델 (Ex.이메일이 스팸인지 아닌지 판별) \n",
    "+ (함수) LogisticRegression, KNN, DecisionTree\n",
    "+ 앙상블 모델 : 여러 개의 기본 모델을 조합하여 하나의 예측 모델을 생성하는 방법, 단일 모델의 한계와 단점 극복\n",
    "+ (함수) RandomForest, XGBoost, LGBM\n",
    "+ 시험에서 머신러닝 파트는 명확한 하이퍼파라미터(조건값)에 따라 정해진 템플릿에 맞춰서\n",
    "+ 조건값을 넣고 코딩하면 되기 때문에 몇 가지 정의된 함수를 습득하면 딥러닝보다 비교적 쉽게 코딩할 수 있습니다.\n",
    "+ <font color=red>(Tip) 머신러닝, 딥러닝 파트는 코드가 길기 때문에 답변 작성 중간에 꼭 [임시저장] 버튼을 클릭해주세요.\n",
    "+ '데이터확인-전처리-AI모델선정-학습데이터 분할>학습>성능평가'의 전반적인 AI모델링 프로세스가 출제됩니다.\n",
    "+ <font color=red>(Tip) 샘플문항을 여러 번 풀어보시고 주요 분류예측 모델과 앙상블 모델별 학습방법을 숙지합시다.\n",
    "+ <span style=\"background-color:#fff6b1\">**[문제]라고 표기된 부분이 실제 점수가 반영되는 시험문제라고 생각하고 더 신경써서 수행해주세요!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB9Zcdvv0FT9"
   },
   "source": [
    "##  <span style=\"background-color:#fff5b1\">학습목차\n",
    "\n",
    " - 데이터 가져오기\n",
    " - 데이터 전처리\n",
    " - Train, Test 데이터셋 분할\n",
    " - 데이터 정규화\n",
    " - 단일 분류예측 모델 : LogisticRegression, KNN, DecisionTree\n",
    " - 앙상블(Ensemble) 모델 : RandomForest, XGBoost, LGBM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V085LH_00FT-"
   },
   "source": [
    "## <span style=\"background-color:#fff5b1\"> [미션] 머신러닝 모델 프로세스 따라가기\n",
    "① 라이브러리 임포트(import)  \n",
    "② 데이터 가져오기(Loading the data)  \n",
    "③ 탐색적 데이터 분석(Exploratory Data Analysis)  \n",
    "④ 데이터 전처리(Data PreProcessing) : 데이터타입 변환, Null 데이터 처리, 누락데이터 처리, \n",
    "더미특성 생성, 특성 추출 \n",
    "⑤ Train, Test  데이터셋 분할  \n",
    "⑥ 데이터 정규화(Normalizing the Data)  \n",
    "⑦ 모델 개발(Creating the Model)  \n",
    "⑧ 모델 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AY9RWMZE0FT_"
   },
   "source": [
    "## ① 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZARhtnLw0FUA"
   },
   "source": [
    "##### 필요 라이브러리를 임포트해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VY4TxgQj0FUA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLHB9VMx0FUC"
   },
   "source": [
    "## ② 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVuC6FaG0FUD"
   },
   "source": [
    "#### data_v1_save.csv 파일 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HvNm0L830FUD"
   },
   "outputs": [],
   "source": [
    "# '01_전처리'에서 저장한 data_v1_save.csv 파일 읽기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4V5lNvqe0FUE"
   },
   "source": [
    "## ③ 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 열, 행 파악하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6v_Ai8e0FUF",
    "outputId": "82f96fa1-3d53-4ca9-f25a-762571b70c02"
   },
   "outputs": [],
   "source": [
    "# info 함수 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "IwQH_hhO0FUG",
    "outputId": "da1f3f21-7695-4556-c77e-e6b90b20ba86"
   },
   "outputs": [],
   "source": [
    "# tail 함수 활용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "Qp-Kap2r0FUG",
    "outputId": "251fddcf-08a5-47ab-9f5b-521ac535db24"
   },
   "outputs": [],
   "source": [
    "# Churn 레이블의 각 고유값 빈도를 계산하여 막대그래프(bar) 그리기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIh8NmeQ0FUH"
   },
   "source": [
    "## ④ 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-nhs1qF0FUH"
   },
   "source": [
    "+ 모든 데이터값들은 숫자형으로 되어야 합니다. 즉, Ojbect 타입을 숫자형으로 변경이 필요합니다.\n",
    "+ Object 컬럼에 대해 Pandas get_dummies 함수를 활용하여 One-Hot-Encoding 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Blq556Xf0FUH",
    "outputId": "2564ea0a-1024-4d8a-dc9f-f86b7c8c9fcb"
   },
   "outputs": [],
   "source": [
    "# MultipleLines 컬럼 내용 보기, head 함수 활용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpzTPy9o0FUI",
    "outputId": "cfeff3a6-4482-4871-bbe3-111660097f01"
   },
   "outputs": [],
   "source": [
    "# MultipleLines 컬럼에 대한 분포 확인 : 3가지(No, Yes, No phone service) 되어 있음 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "CvSKdzeQ0FUI",
    "outputId": "b5896af7-c838-42f5-bd94-88cc068e161a"
   },
   "outputs": [],
   "source": [
    "# MultipleLines 컬럼 값들이 문자열로 되어 있어 숫자로 변환하기\n",
    "# 컴퓨터가 이해할 수 있도록 object 컬럼의 데이터를 원-핫-인코딩해서 숫자로 변경 : Pandas get_dummies()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "2I33ocSP0FUJ",
    "outputId": "9093eade-6200-4aca-f97a-a71b6085fc7d"
   },
   "outputs": [],
   "source": [
    "# object 타입의 컬럼 확인, select_dtypes 함수 활용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRuWYDVt0FUJ",
    "outputId": "3492eb46-8f8d-49ff-bb20-af2779113f77"
   },
   "outputs": [],
   "source": [
    "# object 컬럼명 수집, cal_cols로 저장, 출력\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4ZK1acm0FUK"
   },
   "source": [
    "#####\n",
    "#### <font color=blue> **[문제1] Object 컬럼에 대해 One-Hot-Encoding을 수행하고 그 결과를 df1 변수에 저장하세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nrO_PFhQ0FUK"
   },
   "outputs": [],
   "source": [
    "# Pandas get_dummies() 함수 이용\n",
    "# 원-핫-인코딩 결과를 df1 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKHLRV220FUK",
    "outputId": "f30ab895-a270-4c0e-e92f-850c1f608600"
   },
   "outputs": [],
   "source": [
    "# info 함수 활용, df1의 모든 컬럼 데이터가 숫자형임을 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "jQV1XuM50FUL",
    "outputId": "2bc7170d-fa08-4681-87f3-b3b297e23105"
   },
   "outputs": [],
   "source": [
    "# df1 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_vS5S6s0FUL"
   },
   "source": [
    "## ⑤ Train, Test  데이터셋 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-OtRis00FUL"
   },
   "source": [
    "#### 입력(X)과 레이블(y) 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3uUWsZA0FUM"
   },
   "source": [
    "#### <font color=blue> **[문제2] df1 DataFrame에서 'Churn' 컬럼을 제외한 나머지 정보를 X에 저장하세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sOUAhknI0FUM"
   },
   "outputs": [],
   "source": [
    "# drop 함수 활용, 'Churn' 컬럼 삭제\n",
    "# DataFrame에서 values만 X에 저장\n",
    "# X는 df1으로 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaSeXul50FUM"
   },
   "source": [
    "#### <font color=blue> **[문제3] df DataFrame에서 'Churn' 컬럼을 y로 저장하세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VHOezJtl0FUM"
   },
   "outputs": [],
   "source": [
    "# DataFrame 'Churn' 컬럼 사용\n",
    "# DataFrame에서 values만 y에 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X와 y의 타입을 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfmrbAUZ0FUN"
   },
   "source": [
    "#### Train , test dataset 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-pMRPi50FUN"
   },
   "source": [
    "#### <font color=blue> **[문제4] Train dataset, Test dataset을 나누세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn 라이브러리에서 train_test_split 함수 가져오기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "J9Tpju4m0FUN"
   },
   "outputs": [],
   "source": [
    "# 입력 : X, y \n",
    "# Train : Test 비율 = 7:3\n",
    "# y Class 비율을 유지하면서 나누기 : stratify=y\n",
    "# 여러 번 수행해도 같은 결과 나오게 고정 : random_state=42 \n",
    "# 결과 : X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ylQ-3700FUO",
    "outputId": "a04d9749-fb3c-4ed9-feda-cc18eda784ff"
   },
   "outputs": [],
   "source": [
    "# X_train 배열의 형태 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rg0_4PEk0FUO",
    "outputId": "3abd3937-ba2b-4116-96c2-9f28a679ffa3"
   },
   "outputs": [],
   "source": [
    "# y_train 배열의 형태 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dcPNr_E0FUO"
   },
   "source": [
    "## ⑥ 데이터 정규화/스케일링(Normalizing/Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "mHLW-CRf0FUP",
    "outputId": "9fbcc30f-41cf-4e84-d0e6-0b730d4400c9"
   },
   "outputs": [],
   "source": [
    "# df1, 숫자 분포 이루어진 컬럼 확인, tail 함수 활용\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Q-orGOfi0FUP"
   },
   "outputs": [],
   "source": [
    "# scikit-learn 라이브러리에서 MinMaxScaler 클래스 가져오기\n",
    "# Min-Max는 데이터의 최소값, 최대값을 이용해 데이터를 특정범위(0과 1사이)로 스케일링 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYL7jH_z0FUP"
   },
   "source": [
    "#### <font color=blue> **[문제5] MinMaxScaler 함수를 'scaler'로 정의 하세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ml2_SprW0FUQ"
   },
   "outputs": [],
   "source": [
    "# 정의할 결과를 'scaler'로 매핑, MinMaxScaler 객체를 scaler로 생성\n",
    "# 훈련 데이터에 fit 메서드 적용, transform 메서드로 데이터 변환\n",
    "# 앞서 fit()에서 계산된 최소값과 최대값을 사용하여 테스트 데이터셋 X_test도 동일하게 스케일링\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiM5HomM0FUQ",
    "outputId": "e70a43fc-b274-4f7b-93f9-6e32e595bbc2"
   },
   "outputs": [],
   "source": [
    "# X_train과 y_train에서 처음 두개의 행 가져오기\n",
    "# 데이터가 올바르게 스케일링되었는지 확인 (0과 1 내에 있는지)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⑦ 모델 개발 (참고 코드)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델별 bar 차트를 그려주고, 성능 확인을 시각화하기 위한 함수 코드입니다.\n",
    "#### 시험에는 출제되지 않는 범위이므로 주어진 코드를 실행하고 아래 단계로 넘어가세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별로 Recall 점수 저장\n",
    "# 모델 Recall 점수 순서대로 바차트를 그려 모델별로 성능 확인 가능\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "my_predictions = {}\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
    "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
    "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
    "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
    "         ]\n",
    "\n",
    "# 모델명, 예측값, 실제값을 주면 위의 plot_predictions 함수 호출하여 Scatter 그래프 그리며\n",
    "# 모델별 MSE값을 Bar chart로 그려줌\n",
    "\n",
    "def recall_eval(name_, pred, actual):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    plt.figure(figsize=(12, 9))\n",
    "\n",
    "    #acc = accuracy_score(actual, pred)\n",
    "    acc = recall_score(actual, pred)\n",
    "    my_predictions[name_] = acc * 100\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'recall'])\n",
    "    print(df)\n",
    "   \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['recall'])\n",
    "    \n",
    "    for i, v in enumerate(df['recall']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('recall', fontsize=18)\n",
    "    plt.xlim(0, 100)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⑧ 모델 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWIdyWeg0FUR"
   },
   "source": [
    "###  \n",
    "### **단일 분류 예측 모델**\n",
    "### 1) 로지스틱 회귀 (LogisticRegression, 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "L3x-qaHh0FUR"
   },
   "outputs": [],
   "source": [
    "# 아래 라이브러리를 실행하세요.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2shWVpg00FUS"
   },
   "source": [
    "#### <font color=blue> **[문제6] LogisticRegression 모델을 정의하고 학습시키세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qz_VjrEf0FUS",
    "outputId": "b24a00bb-8300-4b2e-b9d6-21ba486c7730"
   },
   "outputs": [],
   "source": [
    "# LogisticRegression 함수 사용 및 정의 : lg 저장\n",
    "# 정의된 LogisticRegression 학습 fit() : 입력값으로 X_train, y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mW7KXzVL0FUS",
    "outputId": "6f17a240-d5db-4fe2-f0ca-b59ac4395733"
   },
   "outputs": [],
   "source": [
    "# 분류기 성능 평가(score)하기, 1에 가까울수록 모델의 성능 좋음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjYV0iRS0FUS"
   },
   "source": [
    "- 분류기 성능 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Cu1wy0Wt0FUS"
   },
   "outputs": [],
   "source": [
    "# X_test에 대한 예측 수행, predict() 함수 사용\n",
    "# lg_pred로 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DaZFSRr0FUT",
    "outputId": "ea84ed8c-db49-4f99-9744-39e3f4327789"
   },
   "outputs": [],
   "source": [
    "# 모델 성능 평가를 위한 Confusion Matrix 생성(오차행렬)\n",
    "# y_test는 실제 레이블을, lg_pred는 모델이 예측한 레이블\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYM_m9JA0FUT",
    "outputId": "1e530416-548e-4417-b901-93270a1f0bde"
   },
   "outputs": [],
   "source": [
    "# 정확도 구하기(y_test, lg_pred) : 전체 샘플 중 올바르게 예측한 샘플의 비율\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNorqDIl0FUT",
    "outputId": "ab079fd0-9dc8-4528-dff9-dca5e99c4560"
   },
   "outputs": [],
   "source": [
    "# 정밀도 구하기(y_test, lg_pred) : True로 예측한 샘플 중 실제로 True인 샘플의 비율\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQ-B-7U40FUT",
    "outputId": "f9c18954-57fa-4992-f8cf-25c5c5edafe5"
   },
   "outputs": [],
   "source": [
    "# 재현율 구하기(y_test, lg_pred) : 실제 True인 샘플 중 True로 예측한 샘플의 비율\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLMt1bRZ0FUU",
    "outputId": "05b01987-1c85-4471-bad4-0925163923bd"
   },
   "outputs": [],
   "source": [
    "# F1 Score 구하기(y_test, lg_pred) : 정밀도와 재현율의 조화평균\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nw8sNOr90FUU",
    "outputId": "1db6cd44-1c7e-448d-960a-a43be76cb9ce"
   },
   "outputs": [],
   "source": [
    "# LogisticRegression 모델 예측에 대한 분류 리포트 생성, 출력\n",
    "# 정밀도, 재현율, F1-점수와 같은 다양한 분류 지표를 종합적으로 살펴보고, 모델이 클래스를 얼마나 잘 분류하는지\n",
    "# 전체적으로 어떤 성능을 보이는지 판단해보자\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "gV4EhffS0FUU",
    "outputId": "c0ea60e6-825a-4eb1-a4c0-da48a4b639c0"
   },
   "outputs": [],
   "source": [
    "# 참고코드로 제공한 recall_eval 함수 호출\n",
    "# 모델 이름 : LogisticRegression\n",
    "# 예측값 : lg_pred\n",
    "# 실제값 : y_test\n",
    "# 재현율(recall) 계산하고 시각화하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjZAmlXp0FUU"
   },
   "source": [
    "###   \n",
    "### 2) KNN (K-Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "dTLMf6Og0FUU"
   },
   "outputs": [],
   "source": [
    "# KNeighborsClassifier 불러오기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **[문제7] KNN 모델을 정의하고 학습시키세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCAJy-pT0FUV",
    "outputId": "675ba845-6511-4cab-f235-71a33d8c37e2"
   },
   "outputs": [],
   "source": [
    "# n_neighbors=5 설정\n",
    "# fit() 함수 사용, X_train과 y_train 데이터로 모델 학습\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "5LcFquWj0FUV",
    "outputId": "56d60c35-5b56-487d-d647-f090b69c1d72"
   },
   "outputs": [],
   "source": [
    "# recall_eval 함수 호출, KNN 모델의 재현율을 계산하고 시각화하기\n",
    "# knn_pred는 KNN모델 예측 값, y_test는 실제 값\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkXh4Tgu0FUV"
   },
   "source": [
    "###  \n",
    "### 3) 결정트리(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PEPkbbz80FUV"
   },
   "outputs": [],
   "source": [
    "# 아래 라이브러리를 실행하세요.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qEMaN520FUW"
   },
   "source": [
    "#### <font color=blue> **[문제8] 학습된 DecisionTreeClassifier 모델로 예측해 보세요** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_Csk9MqD0FUW"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 학습 모델 : dt\n",
    "# 트리 최대깊이 : 10, random_state=42\n",
    "\n",
    "\n",
    "# fit() 함수 활용하여 모델 학습\n",
    "# 입력값 : X_train, y_train\n",
    "\n",
    "\n",
    "# DecisionTreeClassifier 모델의 predict() 활용 : 입력값으로 X_test\n",
    "# 결과 : dt_pred 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "qhgIeDvs0FUW",
    "outputId": "0df600cc-8607-46f9-8198-effe2b63daa1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recall_eval 함수 호출, DecisionTree 모델의 재현율을 계산하고 시각화하기\n",
    "# dt_pred는 DecisionTree 모델 예측 값, y_test는 실제 값\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y_f-BWX6CCA"
   },
   "source": [
    "###  \n",
    "### **앙상블 기법의 종류**\n",
    "- 배깅 (Bagging) : 여러 개의 모델을 훈련시켜, 그 결과를 결합하여 샘플 중복 생성을 통해 결과 도출(Ex. RandomForest)\n",
    "- 부스팅 (Boosting): 약한 모델을 여러 개 만들어 순차적으로 학습, 이전 학습에 대해 잘못 예측된 데이터에 가중치를 부여, 오차를 보완하는 방식.(Ex. XGBoost, LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtkXJlKj0FUW"
   },
   "source": [
    "![앙상블](https://teddylee777.github.io/images/2019-12-18/image-20191217144823555.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-rwJjK90FUX"
   },
   "source": [
    "###  \n",
    "### 4) 랜덤포레스트(RandomForest)\n",
    "+ Bagging의 대표적인 모델로써, 훈련셋트를 무작위로 각기 다른 서브셋으로 데이터셋을 만들고\n",
    "+ 여러 개의 DecisonTree로 학습하고 다수결로 결정하는 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpOEkIoCAdFd"
   },
   "source": [
    "**주요 Hyperparameter**\n",
    "##### 파라미터들을 조절하면서 모델의 성능을 높이거나 과대적합/과소적합 문제를 해결합니다.\n",
    "\n",
    "- random_state: 랜덤 시드 고정 값. 고정해두고 튜닝하세요!\n",
    "- n_jobs: CPU 사용 갯수 (여러 코어를 사용하면 모델 학습이 빨라짐)\n",
    "- max_depth: 깊어질 수 있는 최대 깊이. 너무 깊은 트리는 과대적합 발생할 수 있음\n",
    "- n_estimators: 앙상블하는 트리의 갯수\n",
    "- max_features: 최대로 사용할 feature의 갯수. 값이 작을수록 과대적합 방지함\n",
    "- min_samples_split: 트리가 분할할 때 필요한 최소 샘플 수. 이 값을 증가시키면 각 분할에 샘플이 많이 필요해서 과대적합 방지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "LfzSa0N60FUX"
   },
   "outputs": [],
   "source": [
    "# 아래 라이브러리를 실행해주세요.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **[문제9] 학습된 RandomForestClassifier 모델로 예측해 보세요** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JegAZUoX0FUX",
    "outputId": "96e8729f-ee39-47fb-db82-a4f89ff28448"
   },
   "outputs": [],
   "source": [
    "# n_estimators=3, random_state=42로 RandomForest 객체 생성 후 rfc에 저장\n",
    "\n",
    "# 훈련 데이터로 모델(rfc) 훈련\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "yd3AA9mFa_0n"
   },
   "outputs": [],
   "source": [
    "# X_test를 사용하여 rfc 모델로 예측, 결과를 rfc_pred에 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "-RkzXSShS6ks",
    "outputId": "e3cdf947-b72d-4cef-d795-5ec334ab602d"
   },
   "outputs": [],
   "source": [
    "# recall_eval 함수 호출, 'RandomForest Ensemble' 모델의 rfc_pred, y_test를 사용해 재현율 평가 실행\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxLwe2Qw0FUY"
   },
   "source": [
    "###  \n",
    "### 5) XGBoost\n",
    "+ 여러 개의 약한 DecisionTree를 결합하여 강력한 예측모델을 만드는 Boosting 방식을 사용하는 앙상블 기법\n",
    "+ Kaggle 대회에서 자주 사용하는 모델이며, 실제 업계에서도 높은 성능을 지닌 예측 모델을 만드는데 활용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw17wJya85Ms"
   },
   "source": [
    "**주요 특징**\n",
    "- scikit-learn 패키지가 아닙니다.\n",
    "- 효율적인 알고리즘과 여러 최적화 기술로 성능이 우수함\n",
    "- GBM보다는 빠르고 성능도 향상되었습니다.\n",
    "- 대규모 데이터셋엥서는 학습 시간이 오래 걸릴 수 있음\n",
    "- 데이터셋이 작거나 노이즈가 많은 경우, 과적합 위험이 있음 (트리 최대깊이 지정 등 완화)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fAjfIX9Jpcx"
   },
   "source": [
    "**주요 Hyperparameter**\n",
    "- random_state: 랜덤 시드 고정 값. 고정해두고 튜닝하세요!\n",
    "- n_jobs: CPU 사용 갯수 (여러 코어를 사용하면 모델 학습이 빨라짐)\n",
    "- learning_rate: 학습율. 너무 큰 학습율은 성능이 떨어질 수 있고 너무 낮으면 학습이 느려져서 적절한 값을 찾아야 함, default=0.1\n",
    "- n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100\n",
    "- max_depth: 트리의 깊이. 너무 높으면 과적합, 너무 낮으면 성능이 떨어짐. default=3. \n",
    "- subsample: 샘플 사용 비율(0~1 사이의 값), 과대적합 방지용.\n",
    "- max_features: 최대로 사용할 feature의 비율. 과대적합 방지용. default=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABeT1Opy0FUY",
    "outputId": "cec43e50-ffd1-4bab-af84-a87cefeb9aff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (1.7.4)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 패키지를 pip을 통해 설치\n",
    "\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "LH2Plwt60FUZ"
   },
   "outputs": [],
   "source": [
    "# 아래 라이브러리를 실행하세요.\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **[문제10] 학습된 XGBoostClassifier 모델로 예측해 보세요** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hygo7t_j0FUZ",
    "outputId": "74c1e08e-c7a9-4bea-b3dd-b23a57876167"
   },
   "outputs": [],
   "source": [
    "# XGBoost 분류기 생성(xgb 변수 저장), 학습 데이터로 모델 훈련\n",
    "# n_estimators=3, random_state=42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "YiIBtKi80FUZ"
   },
   "outputs": [],
   "source": [
    "# X_test를 사용해 XGBoost 모델로 예측값 생성하고 xgb_pred에 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "kAKKoLLh0FUZ",
    "outputId": "10d769a9-f45e-4d43-d577-4ab488d2a88c"
   },
   "outputs": [],
   "source": [
    "# recall_eval 함수 호출, 'XGBoost' 모델의 예측 결과를 사용해 재현율 평가\n",
    "# 인수 : xgb_pred, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUvyyQcM0FUZ"
   },
   "source": [
    "###  \n",
    "### 6) Light GBM\n",
    "+ XGBoost와 함께 주목받는 DecisionTree 알고리즘 기반의 Boosting 방식의 앙상블 기법\n",
    "+ XGBoost에 비해 학습시간이 짧은 편이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Unk2_LocLD_I"
   },
   "source": [
    "**주요 특징**\n",
    "- scikit-learn 패키지가 아닙니다.\n",
    "- 효율성과 성능이 우수함\n",
    "- 속도도 매우 빠릅니다.\n",
    "- 낮은 메모리를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaKdEHJpLrm4"
   },
   "source": [
    "**주요 Hyperparameter**\n",
    "- random_state: 랜덤 시드 고정 값. 고정해두고 튜닝하세요!\n",
    "- n_jobs: CPU 사용 갯수 (여러 코어를 사용하면 모델 학습이 빨라짐)\n",
    "- learning_rate: 학습율. 이 값이 너무 높으면 과적합할 수 있고 낮으면 학습이 느려질 수 있음. 적절한 값을 찾아야함. default=0.1\n",
    "- n_estimators: 부스팅 스테이지 수.(랜덤포레스트 트리의 갯수와 비슷한 개념). 높을수록 복잡성 증가함. default=100\n",
    "- max_depth: 트리의 깊이. 값이 크면 과적합 위험이 있음. default=3. \n",
    "- colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeMfBOjQ0FUa",
    "outputId": "37b789ab-e898-463b-ea50-d37ffdb86515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (3.3.5)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: wheel in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Light GBM 패키지를 pip을 통해 설치\n",
    "\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "190g_jQU0FUa"
   },
   "outputs": [],
   "source": [
    "# 아래 라이브러리를 실행하세요.\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=blue> **[문제11] 학습된 LGBMClassifier 모델로 예측해 보세요** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34NklLzz0FUa",
    "outputId": "bfde9023-41f3-481e-910d-7f7883c5018f"
   },
   "outputs": [],
   "source": [
    "# LGBM 모델 생성. n_estimators=3, random_state=42\n",
    "\n",
    "\n",
    "# X_train과 y_train 데이터를 사용해 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IqymXJLO0FUa"
   },
   "outputs": [],
   "source": [
    "# X_test 데이터를 사용해 예측을 수행하고, lgbm_pred 변수에 저장\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "wBLc6O9q0FUb",
    "outputId": "dbe4570f-e313-4f9c-b30f-3a9d27110663"
   },
   "outputs": [],
   "source": [
    "# 'LGBM' 모델의 재현율을 평가하고 시각화. 예측값은 lgbm_pred, 실제값은 y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEYoahG80FUb",
    "outputId": "fed70c62-0759-409d-faa7-23c665d71609"
   },
   "outputs": [],
   "source": [
    "# LGBM 모델의 정확도를 평가하시오. X_test, y_test 사용.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzHQwJBf0FUb",
    "outputId": "8acaae40-8784-49ee-e595-b7be6661db57"
   },
   "outputs": [],
   "source": [
    "# LGBM 모델의 재현율 평가. 실제 라벨 y_test와 모델의 예측값 lgbm_pred 사용.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLSjCzg80FUc"
   },
   "source": [
    "## <span style=\"background-color:#fff5b1\"> 이제까지 머신러닝에서 수행한 내용을 한번 볼까요?\n",
    "\n",
    "**1. 머신러닝 모델 프로세스**\n",
    "    \n",
    "##### ① 라이브러리 임포트(import)  \n",
    "##### ② 데이터 가져오기(Loading the data)  \n",
    "##### ③ 탐색적 데이터 분석(Exploratory Data Analysis)  \n",
    "##### ④ 데이터 전처리(Data PreProcessing) : 데이터타입 변환, Null 처리, 누락데이터 처리, 원-핫 인코딩, 문자열 또는 범주형 데이터 처리  \n",
    "##### ⑤ Train, Test  데이터셋 분할 : 70-30으로 나누어 훈련 \n",
    "##### ⑥ 데이터 정규화/스케일링(Normalizing the Data) : 주로 0과 1사이 범위로 조정 / 데이터의 단위 일치\n",
    "##### ⑦ 모델 개발(Creating the Model) : 모델별 bar 차트를 그려주고, 성능 확인을 시각화하기 위한 함수 제공\n",
    "##### ⑧ 모델 성능 평가\n",
    "\n",
    "**2. 평가 지표 활용 : 모델별 성능 확인을 위한 함수 (제공된 함수를 가져다 쓰면 된다!)**\n",
    "\n",
    "**3. 단일 회귀예측 모델 : LogisticRegression, KNN, DecisionTree**\n",
    "\n",
    "**4. 앙상블 (Ensemble) : RandomForest, XGBoost, LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rI_eIYrz0FUc"
   },
   "source": [
    "#### **조별실습-머신러닝 파트를 수행하시느라 고생 많으셨습니다.**\n",
    "\n",
    "#### **완성하신 조는 '03_딥러닝' 파일을 수행해주세요!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Python활용AI모델링_02.머신러닝_퀴즈_v3_20220219.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
